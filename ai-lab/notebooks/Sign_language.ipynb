{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sign Language Model (Sign MNIST)\n",
        "\n",
        "Stages:\n",
        "1. Environment + Imports\n",
        "2. Load CSV Data (Sign MNIST)\n",
        "3. Train XGBoost Model\n",
        "4. Evaluate\n",
        "5. Save Model\n",
        "6. Export to ONNX\n",
        "\n",
        "**Note**: We use `onnxmltools` to convert XGBoost models to ONNX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.4.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.0)\n",
            "Requirement already satisfied: xgboost in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2.0)\n",
            "Requirement already satisfied: skl2onnx in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.20.0)\n",
            "Requirement already satisfied: onnx in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.20.1)\n",
            "Requirement already satisfied: onnxmltools in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnx) (0.5.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 26.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# 1. Environment + Imports\n",
        "%pip install pandas numpy scikit-learn xgboost skl2onnx onnx onnxmltools\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "import onnxmltools\n",
        "from onnxmltools.convert import convert_xgboost\n",
        "from onnxmltools.convert.common.data_types import FloatTensorType\n",
        "import onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading train data from ../data/asl_alphabet/sign_mnist_train.csv...\n",
            "Train shape: (27455, 785)\n",
            "Loading test data from ../data/asl_alphabet/sign_mnist_test.csv...\n"
          ]
        }
      ],
      "source": [
        "# 2. Load CSV Data\n",
        "train_path = '../data/asl_alphabet/sign_mnist_train.csv'\n",
        "test_path = '../data/asl_alphabet/sign_mnist_test.csv'\n",
        "\n",
        "if os.path.exists(train_path):\n",
        "    print(f\"Loading train data from {train_path}...\")\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    print(f\"Train shape: {train_df.shape}\")\n",
        "    \n",
        "    # Sign MNIST format: 'label', pixel1, pixel2, ...\n",
        "    X_train = train_df.drop('label', axis=1)\n",
        "    y_train = train_df['label']\n",
        "    \n",
        "    # Normalize pixels 0-1\n",
        "    X_train = X_train / 255.0\n",
        "    \n",
        "else:\n",
        "    print(\"WARNING: Train CSV not found!\")\n",
        "    \n",
        "if os.path.exists(test_path):\n",
        "    print(f\"Loading test data from {test_path}...\")\n",
        "    test_df = pd.read_csv(test_path)\n",
        "    \n",
        "    X_test = test_df.drop('label', axis=1)\n",
        "    y_test = test_df['label']\n",
        "    X_test = X_test / 255.0\n",
        "else:\n",
        "    print(\"WARNING: Test CSV not found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training XGBoost... this might take a minute.\n",
            "Training done.\n"
          ]
        }
      ],
      "source": [
        "# 3. Train XGBoost Model\n",
        "\n",
        "if 'X_train' in locals():\n",
        "    # Encode labels\n",
        "    le = LabelEncoder()\n",
        "    y_train_encoded = le.fit_transform(y_train)\n",
        "    if 'y_test' in locals():\n",
        "        y_test_encoded = le.transform(y_test)\n",
        "\n",
        "    print(\"Training XGBoost... this might take a minute.\")\n",
        "    # Using tree_method='hist' for speed\n",
        "    model = XGBClassifier(eval_metric='mlogloss', n_estimators=100, tree_method='hist')\n",
        "    model.fit(X_train, y_train_encoded)\n",
        "    print(\"Training done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7663134411600669\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.97      0.91       331\n",
            "           1       0.96      0.89      0.93       432\n",
            "           2       0.93      0.91      0.92       310\n",
            "           3       0.86      0.98      0.92       245\n",
            "           4       0.82      0.89      0.85       498\n",
            "           5       0.79      0.92      0.85       247\n",
            "           6       0.89      0.81      0.85       348\n",
            "           7       0.97      0.90      0.94       436\n",
            "           8       0.80      0.69      0.74       288\n",
            "           9       0.77      0.64      0.70       331\n",
            "          10       0.79      0.99      0.88       209\n",
            "          11       0.77      0.60      0.67       394\n",
            "          12       0.70      0.40      0.51       291\n",
            "          13       0.93      0.68      0.79       246\n",
            "          14       0.93      0.97      0.95       347\n",
            "          15       0.66      0.95      0.78       164\n",
            "          16       0.24      0.44      0.31       144\n",
            "          17       0.47      0.61      0.53       246\n",
            "          18       0.56      0.67      0.61       248\n",
            "          19       0.62      0.62      0.62       266\n",
            "          20       0.82      0.60      0.69       346\n",
            "          21       0.49      0.70      0.58       206\n",
            "          22       0.79      0.69      0.74       267\n",
            "          23       0.72      0.63      0.67       332\n",
            "\n",
            "    accuracy                           0.77      7172\n",
            "   macro avg       0.76      0.76      0.75      7172\n",
            "weighted avg       0.79      0.77      0.77      7172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 4. Evaluate\n",
        "\n",
        "if 'model' in locals() and 'X_test' in locals():\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Accuracy: {accuracy_score(y_test_encoded, y_pred)}\")\n",
        "    print(classification_report(y_test_encoded, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to ../src\n"
          ]
        }
      ],
      "source": [
        "# 5. Save Model\n",
        "\n",
        "if 'model' in locals():\n",
        "    src_dir = '../src'\n",
        "    os.makedirs(src_dir, exist_ok=True)\n",
        "    joblib.dump(model, os.path.join(src_dir, 'model.joblib'))\n",
        "    joblib.dump(le, os.path.join(src_dir, 'label_encoder.joblib'))\n",
        "    print(f\"Model saved to {src_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converting to ONNX using onnxmltools...\n",
            "ONNX model saved to ..\\..\\web-app\\public\\models\\model.onnx\n"
          ]
        }
      ],
      "source": [
        "# 6. Export to ONNX\n",
        "\n",
        "if 'model' in locals():\n",
        "    print(\"Converting to ONNX using onnxmltools...\")\n",
        "    \n",
        "    # Re-import to ensure it's available\n",
        "    try:\n",
        "        from onnxmltools.convert import convert_xgboost\n",
        "        from onnxmltools.convert.common.data_types import FloatTensorType\n",
        "    except ImportError:\n",
        "        print(\"Creating fallback import... please run cell 1 to install onnxmltools\")\n",
        "        %pip install onnxmltools\n",
        "        import onnxmltools\n",
        "        from onnxmltools.convert import convert_xgboost\n",
        "        from onnxmltools.convert.common.data_types import FloatTensorType\n",
        "\n",
        "    model.get_booster().feature_names = [f'f{i}' for i in range(X_train.shape[1])]\n",
        "    n_features = X_train.shape[1]\n",
        "    initial_type = [('float_input', FloatTensorType([None, n_features]))]\n",
        "    \n",
        "    # Use onnxmltools.convert_xgboost for XGBoost models\n",
        "    onnx_model = convert_xgboost(model, initial_types=initial_type)\n",
        "    \n",
        "    public_dir = os.path.join('..', '..', 'web-app', 'public','models')\n",
        "    os.makedirs(public_dir, exist_ok=True)\n",
        "    \n",
        "    onnx_path = os.path.join(public_dir, 'model.onnx')\n",
        "    with open(onnx_path, \"wb\") as f:\n",
        "        f.write(onnx_model.SerializeToString())\n",
        "    print(f\"ONNX model saved to {onnx_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
